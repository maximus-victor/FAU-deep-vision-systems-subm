{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepVis_IMAGE_CLASSIFICATION_FINAL_TEST.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a6e5f27ae4f4b8badb8b4a4526cd3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_options_labels": [
              "BaseNet",
              "ResNet18",
              "RegNet",
              "VicNet",
              "VGG16"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_054f0c3df1214e0c81ffa79b8297b2de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "DropdownModel",
            "index": 0,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_361f140cc9304137bbdf61236b63ab6f"
          }
        },
        "054f0c3df1214e0c81ffa79b8297b2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "361f140cc9304137bbdf61236b63ab6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maximus-victor/FAU-deep-vision-systems-subm/blob/main/DeepVis_IMAGE_CLASSIFICATION_FINAL_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhfYsYKKOShL"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb56WsVKxiTk"
      },
      "source": [
        "## RegNet\n",
        "config = dict(\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    learning_rate=0.001,\n",
        "    dropout=0.3,\n",
        "    fc_layer_size=256,\n",
        "    kernel_size=5,\n",
        "    optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOfpWaZUdeKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "535fe59a-fef1-471f-a6dd-4eafbeb28b6c"
      },
      "source": [
        "\"\"\"\n",
        "## VGG16\n",
        "config = dict(\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    learning_rate=0.0001,\n",
        "    optimizer='adam') \n",
        "\n",
        "## ResNet18\n",
        "config = dict(\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    learning_rate=0.0001,\n",
        "    optimizer='adam') \n",
        "\n",
        "## RegNet\n",
        "config = dict(\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    learning_rate=0.001,\n",
        "    dropout=0.3,\n",
        "    fc_layer_size=256,\n",
        "    kernel_size=5,\n",
        "    optimizer='adam')\n",
        "\n",
        "## BaseNet\n",
        "config = dict(\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    learning_rate=0.001,\n",
        "    optimizer='adam')\n",
        "\n",
        "## VicNet\n",
        "config = dict(\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    learning_rate=0.00003,\n",
        "    dropout=0.5,\n",
        "    kernel_size=3,\n",
        "    fc_layer_size=256,\n",
        "    optimizer='adam')\n",
        "\n",
        "## MaxNet\n",
        "config = dict(\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    learning_rate=0.00003,\n",
        "    fc_layer_size=256,\n",
        "    optimizer='adam')\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n## VGG16\\nconfig = dict(\\n    epochs=200,\\n    batch_size=64,\\n    learning_rate=0.0001,\\n    optimizer='adam') \\n\\n## ResNet18\\nconfig = dict(\\n    epochs=200,\\n    batch_size=64,\\n    learning_rate=0.0001,\\n    optimizer='adam') \\n\\n## RegNet\\nconfig = dict(\\n    epochs=200,\\n    batch_size=64,\\n    learning_rate=0.001,\\n    dropout=0.3,\\n    fc_layer_size=256,\\n    kernel_size=5,\\n    optimizer='adam')\\n\\n## BaseNet\\nconfig = dict(\\n    epochs=200,\\n    batch_size=64,\\n    learning_rate=0.001,\\n    optimizer='adam')\\n\\n## VicNet\\nconfig = dict(\\n    epochs=150,\\n    batch_size=32,\\n    learning_rate=0.00003,\\n    dropout=0.5,\\n    kernel_size=3,\\n    fc_layer_size=256,\\n    optimizer='adam')\\n\\n## MaxNet\\nconfig = dict(\\n    epochs=150,\\n    batch_size=32,\\n    learning_rate=0.00003,\\n    fc_layer_size=256,\\n    optimizer='adam')\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKHyzOYr01T5"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-9Tl-RFlz6_"
      },
      "source": [
        "## Libraries & Seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3F2Y50clwfU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from imutils import paths\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFOgfCKiDQ9n"
      },
      "source": [
        "The next block of code applies a seed to our code for reproducibility and also sets the computation device. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI7IK0e8DOj0",
        "outputId": "84b934f0-f6c3-4226-aa1c-f4658c385dca"
      },
      "source": [
        "def seed_libraries(SEED=42):\n",
        "  # Python seeds\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  # Torch seeds\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "SEED=42\n",
        "seed_libraries(SEED=SEED)\n",
        "\n",
        "\n",
        "# set computation device\n",
        "runtime = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Computation device: {runtime}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computation device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-un7U53amuuz"
      },
      "source": [
        "# **Set Dicitonaries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-a88VYLm0Ya"
      },
      "source": [
        "**Google Drive Version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPPN1MqumuRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c023ecfa-9a52-4c7c-acb7-741839792dc8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-lDCvDGoeJV"
      },
      "source": [
        "# !unzip /content/drive/MyDrive/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDj_9b9Sm9RM"
      },
      "source": [
        "DIR_DATEN = \"/content/drive/MyDrive/DEEPVIS/data\"   # make sure to always adapt this to your own folser structure\n",
        "#DIR_DATEN = \"/content/drive/MyDrive/001_university/001_FAU/002_IIS/DVS/wafer_data/\" # Max\n",
        "DIR_DATEN_01 = os.path.join(DIR_DATEN, \"01_Daten\")\n",
        "DIR_WAFER_IMAGES = os.path.join(DIR_DATEN, \"WaferImages\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sCZ10w5ODGv"
      },
      "source": [
        "## **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3V0mipE82yk"
      },
      "source": [
        "labels_filename =\"Labels_Waferviertel.xlsx\"\n",
        "meta_filename = \"Meta_data.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIpv38AzOIAT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "a65f5893-32f8-4713-887f-a66582116265"
      },
      "source": [
        "labels = pd.read_excel(os.path.join(DIR_DATEN_01, labels_filename))\n",
        "labels.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>Part No</th>\n",
              "      <th>Crack</th>\n",
              "      <th>Patch</th>\n",
              "      <th>Scratch</th>\n",
              "      <th>Low Level</th>\n",
              "      <th>Circle</th>\n",
              "      <th>Displaced</th>\n",
              "      <th>Splinter</th>\n",
              "      <th>Stain</th>\n",
              "      <th>Wafer on Pin</th>\n",
              "      <th>Other</th>\n",
              "      <th>PosX</th>\n",
              "      <th>PosY</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>PreviousClass</th>\n",
              "      <th>NoOfErrors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001932631.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:45</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001932631.tif</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:45</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001932631.tif</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:45</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001932631.tif</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:45</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001945868.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:47</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       File Name  Part No  Crack  ...            Timestamp  PreviousClass  NoOfErrors\n",
              "0  001932631.tif        0  False  ...  2019-06-12 13:48:45          other           1\n",
              "1  001932631.tif        1  False  ...  2019-06-12 13:48:45          other           1\n",
              "2  001932631.tif        2  False  ...  2019-06-12 13:48:45          other           1\n",
              "3  001932631.tif        3  False  ...  2019-06-12 13:48:45          other           1\n",
              "4  001945868.tif        0  False  ...  2019-06-12 13:48:47          other           1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFUdpMtCOJ_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2beed864-def3-4bb4-d80d-ea17d6ded896"
      },
      "source": [
        "labels[\"PreviousClass\"].unique()  # we don't need that any longer?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['other', 'patch', 'circle', 'splinter', 'stain', 'waferonpin',\n",
              "       'crack', 'scratch'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHsIgaSOMoA"
      },
      "source": [
        "## **Meta-Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQymXrZ1OQK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ff72f5-35f0-4dc4-a53d-75e7c706319e"
      },
      "source": [
        "meta = pd.read_csv(os.path.join(DIR_DATEN_01, meta_filename))\n",
        "meta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>wafer_id</th>\n",
              "      <th>gray_mean</th>\n",
              "      <th>class</th>\n",
              "      <th>NameBild</th>\n",
              "      <th>SUBSTRATEIDENT</th>\n",
              "      <th>TIMESTAMP_CTS</th>\n",
              "      <th>CTS_EFF</th>\n",
              "      <th>CTS_FF</th>\n",
              "      <th>CTS_VOC</th>\n",
              "      <th>CTS_ISC</th>\n",
              "      <th>CTS_RSER</th>\n",
              "      <th>CTS_RSH</th>\n",
              "      <th>CTS_IREV2_T</th>\n",
              "      <th>CTS_B2B_1</th>\n",
              "      <th>CTS_JOB_NR</th>\n",
              "      <th>CTS_EL_CRACK_COUNT</th>\n",
              "      <th>CTS_EL_DARKAREA_COUNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002152418.tif</td>\n",
              "      <td>2152418</td>\n",
              "      <td>183.47</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>002152418.tif</td>\n",
              "      <td>11790109.0</td>\n",
              "      <td>2018-07-26 14:46:26</td>\n",
              "      <td>23.136937</td>\n",
              "      <td>0.814332</td>\n",
              "      <td>737.587</td>\n",
              "      <td>9.412589</td>\n",
              "      <td>4.987</td>\n",
              "      <td>4481.251483</td>\n",
              "      <td>0.331505</td>\n",
              "      <td>20.010000</td>\n",
              "      <td>20180726 Exp 66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001889692.tif</td>\n",
              "      <td>1889692</td>\n",
              "      <td>176.80</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>001889692.tif</td>\n",
              "      <td>11232718.0</td>\n",
              "      <td>2018-02-27 13:19:22</td>\n",
              "      <td>23.041940</td>\n",
              "      <td>0.810728</td>\n",
              "      <td>735.176</td>\n",
              "      <td>9.445444</td>\n",
              "      <td>5.032</td>\n",
              "      <td>3471.378009</td>\n",
              "      <td>0.040560</td>\n",
              "      <td>35.639999</td>\n",
              "      <td>20180227 HD556</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001897005.tif</td>\n",
              "      <td>1897005</td>\n",
              "      <td>177.04</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>001897005.tif</td>\n",
              "      <td>11278998.0</td>\n",
              "      <td>2018-03-05 15:07:20</td>\n",
              "      <td>23.073799</td>\n",
              "      <td>0.811632</td>\n",
              "      <td>735.720</td>\n",
              "      <td>9.441592</td>\n",
              "      <td>4.906</td>\n",
              "      <td>3821.416372</td>\n",
              "      <td>0.021333</td>\n",
              "      <td>38.169998</td>\n",
              "      <td>20180305 HD547-4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001962325.tif</td>\n",
              "      <td>1962325</td>\n",
              "      <td>172.97</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>001962325.tif</td>\n",
              "      <td>11403759.0</td>\n",
              "      <td>2018-04-04 11:41:30</td>\n",
              "      <td>22.571537</td>\n",
              "      <td>0.797088</td>\n",
              "      <td>734.655</td>\n",
              "      <td>9.417174</td>\n",
              "      <td>5.329</td>\n",
              "      <td>3016.940429</td>\n",
              "      <td>0.006562</td>\n",
              "      <td>38.720001</td>\n",
              "      <td>20180328 M2R</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>002152288.tif</td>\n",
              "      <td>2152288</td>\n",
              "      <td>173.58</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>002152288.tif</td>\n",
              "      <td>11794609.0</td>\n",
              "      <td>2018-07-26 14:34:30</td>\n",
              "      <td>23.001560</td>\n",
              "      <td>0.810923</td>\n",
              "      <td>735.170</td>\n",
              "      <td>9.428756</td>\n",
              "      <td>5.170</td>\n",
              "      <td>1169.261436</td>\n",
              "      <td>0.182121</td>\n",
              "      <td>20.059999</td>\n",
              "      <td>20180726 Exp 66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6101</th>\n",
              "      <td>002126113.tif</td>\n",
              "      <td>2126113</td>\n",
              "      <td>213.27</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002126113.tif</td>\n",
              "      <td>11734418.0</td>\n",
              "      <td>2018-07-02 11:44:45</td>\n",
              "      <td>23.665103</td>\n",
              "      <td>0.821231</td>\n",
              "      <td>744.152</td>\n",
              "      <td>9.462665</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4500.504749</td>\n",
              "      <td>0.009221</td>\n",
              "      <td>43.840000</td>\n",
              "      <td>20180702 EXP41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>002160320.tif</td>\n",
              "      <td>2160320</td>\n",
              "      <td>172.81</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002160320.tif</td>\n",
              "      <td>11825342.0</td>\n",
              "      <td>2018-08-02 10:34:09</td>\n",
              "      <td>22.769944</td>\n",
              "      <td>0.800344</td>\n",
              "      <td>734.057</td>\n",
              "      <td>9.471267</td>\n",
              "      <td>5.318</td>\n",
              "      <td>25349.092305</td>\n",
              "      <td>0.000851</td>\n",
              "      <td>19.879999</td>\n",
              "      <td>20180802 EXP 99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6103</th>\n",
              "      <td>002161033.tif</td>\n",
              "      <td>2161033</td>\n",
              "      <td>201.44</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002161033.tif</td>\n",
              "      <td>11827179.0</td>\n",
              "      <td>2018-08-02 11:35:48</td>\n",
              "      <td>23.229798</td>\n",
              "      <td>0.811132</td>\n",
              "      <td>740.253</td>\n",
              "      <td>9.453416</td>\n",
              "      <td>4.889</td>\n",
              "      <td>14218.466321</td>\n",
              "      <td>0.001039</td>\n",
              "      <td>22.299999</td>\n",
              "      <td>20180802 EXP 99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6104</th>\n",
              "      <td>002161876.tif</td>\n",
              "      <td>2161876</td>\n",
              "      <td>194.77</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002161876.tif</td>\n",
              "      <td>11807331.0</td>\n",
              "      <td>2018-08-03 12:47:42</td>\n",
              "      <td>23.060322</td>\n",
              "      <td>0.810989</td>\n",
              "      <td>736.246</td>\n",
              "      <td>9.435790</td>\n",
              "      <td>5.220</td>\n",
              "      <td>2525.808870</td>\n",
              "      <td>0.008307</td>\n",
              "      <td>26.870001</td>\n",
              "      <td>20180803 EXP 58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6105</th>\n",
              "      <td>002161769.tif</td>\n",
              "      <td>2161769</td>\n",
              "      <td>183.17</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002161769.tif</td>\n",
              "      <td>11806845.0</td>\n",
              "      <td>2018-08-03 12:35:43</td>\n",
              "      <td>23.053969</td>\n",
              "      <td>0.812255</td>\n",
              "      <td>735.366</td>\n",
              "      <td>9.430334</td>\n",
              "      <td>4.984</td>\n",
              "      <td>3382.212480</td>\n",
              "      <td>0.019721</td>\n",
              "      <td>24.680000</td>\n",
              "      <td>20180803 EXP 58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6106 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          file_name  wafer_id  ...  CTS_EL_CRACK_COUNT CTS_EL_DARKAREA_COUNT\n",
              "0     002152418.tif   2152418  ...                 0.0                   0.0\n",
              "1     001889692.tif   1889692  ...                 1.0                   0.0\n",
              "2     001897005.tif   1897005  ...                 0.0                   0.0\n",
              "3     001962325.tif   1962325  ...                 1.0                   0.0\n",
              "4     002152288.tif   2152288  ...                 0.0                   0.0\n",
              "...             ...       ...  ...                 ...                   ...\n",
              "6101  002126113.tif   2126113  ...                 0.0                   0.0\n",
              "6102  002160320.tif   2160320  ...                 0.0                   0.0\n",
              "6103  002161033.tif   2161033  ...                 0.0                   0.0\n",
              "6104  002161876.tif   2161876  ...                 0.0                   0.0\n",
              "6105  002161769.tif   2161769  ...                 0.0                   0.0\n",
              "\n",
              "[6106 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6-xtJ2pOTm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85523c24-3a22-4abe-8ddb-8181cb7406c4"
      },
      "source": [
        "meta[\"class\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Cracks', 'Flecken', 'Kratzer', 'low_level', 'Punkte',\n",
              "       'schlecht_positioniert', 'Sonstiges', 'Splitter_im_Tester',\n",
              "       'Verschmutzung', 'Wafer_auf_Pin', 'gute_Wafer'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8saJb3ZOZE_"
      },
      "source": [
        "## **Load, Select and Encode Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbFXue0gObud",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29e60d2a-c492-432f-e62b-7833f8af235b"
      },
      "source": [
        "list(paths.list_images(DIR_WAFER_IMAGES))[0].split(os.path.sep)[-2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stain'"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTuXl_7GOdcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc3f278-d9cc-4a9c-cea6-30bdec7e182d"
      },
      "source": [
        "# get all the image paths\n",
        "image_paths = list(paths.list_images(DIR_WAFER_IMAGES))\n",
        "\n",
        "# create an empty DataFrame\n",
        "data = pd.DataFrame()\n",
        "\n",
        "for i, image_path in tqdm(enumerate(image_paths), total=len(image_paths)):\n",
        "    data.loc[i, 'label'] = image_path.split(os.path.sep)[-2]  # loading labels into DataFrame based on directory name\n",
        "    data.loc[i, 'image_path'] = image_path # loading image paths into DataFrame\n",
        "\n",
        "print(data.head())\n",
        "print('\\n')\n",
        "print(\"Unique classes: \", data.label.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5944/5944 [00:04<00:00, 1411.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   label                                         image_path\n",
            "0  stain  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "1  stain  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "2  stain  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "3  stain  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "4  stain  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "\n",
            "\n",
            "Unique classes:  ['stain' 'scratch' 'other' 'good' 'low_level' 'displaced' 'patch' 'crack'\n",
            " 'splinter' 'waferonpin' 'circle']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6C2WFcvZiSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2601ef6e-1234-48dc-867d-7070bbf64d0e"
      },
      "source": [
        "## 6 classes\n",
        "# sel_classes = ['circle', 'crack', 'good', 'scratch', 'splinter', 'stain'] # selecting bounding boxes classes\n",
        "## 3 classes\n",
        "# sel_classes = ['good', 'low_level', 'circle'] # selecting easiest visually recognisable classes\n",
        "## 11 classs \n",
        "sel_classes = ['stain', 'scratch', 'other', 'good', 'low_level', 'displaced', 'patch', 'crack', 'splinter', 'waferonpin', 'circle']\n",
        "data = data[data['label'].isin(sel_classes)] # reducing DataFrame to the selected classes\n",
        "\n",
        "\n",
        "data.label.unique()\n",
        "\n",
        "lb = preprocessing.LabelEncoder() # encoding target labels with values between 0 and n_classes-1\n",
        "data['label'] = lb.fit_transform(data['label']) #  appling encoded labels to our DataFrame data\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label                                         image_path\n",
            "0      9  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "1      9  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "2      9  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "3      9  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "4      9  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DTEpnmEVT0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f583ab52-8d13-4ccc-bc50-116b1c2bba36"
      },
      "source": [
        "len(lb.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7O9a1SVZ8Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4ecc6b-4d93-495d-bda6-eb740c16af04"
      },
      "source": [
        "mapping = dict(zip(lb.classes_, lb.transform(lb.classes_)))\n",
        "inverse_mapping = dict(zip(lb.transform(lb.classes_), lb.classes_))\n",
        "\n",
        "print(\"Mapping label to class:\")\n",
        "print('\\n')\n",
        "print(inverse_mapping)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mapping label to class:\n",
            "\n",
            "\n",
            "{0: 'circle', 1: 'crack', 2: 'displaced', 3: 'good', 4: 'low_level', 5: 'other', 6: 'patch', 7: 'scratch', 8: 'splinter', 9: 'stain', 10: 'waferonpin'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dmGXH7IQ5C7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7554926f-6db0-4328-d947-e86b6bedbfac"
      },
      "source": [
        "values = data.label.value_counts() # plotting the number of occurrences of each label\n",
        "classes = [inverse_mapping[i] for i in values.index]\n",
        "plt.barh(classes, values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 11 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 280
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD4CAYAAAA6j0u4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAae0lEQVR4nO3debhcVZnv8e/PhCEJGQhEbsDhqOQRwxRCgkQIDRjTgNi0VyQiXhn0xukq2B1tbPoKtKJAeFpsRDBNIyhcpElDi7E1YhgSmZKTOUEC2EaZJQ2GISAhvPePvQ5WDlU5dZJaVbvO+X2ep57atfbaq9bKTvKetfY++1VEYGZmltMbWt0BMzPr+xxszMwsOwcbMzPLzsHGzMyyc7AxM7PsBra6A2W16667RkdHR6u7YWbWVhYvXrwuIkZ1L3ewqaGjo4POzs5Wd8PMrK1I+l21ci+jmZlZdg42ZmaWnYONmZll52BjZmbZOdiYmVl2DjZmZpadg42ZmWXnYGNmZtn5lzprWPnoejrO/GmWttee//4s7ZqZlZVnNmZmlp2DjZmZZedgY2Zm2ZUy2Eg6R9KMtP2Pkqb0UP9wSe9pTu/MzKy3Sn+DQER8tY5qhwPPA3fV266kgRHxytb2y8zM6te0mY2kIZJ+Kmm5pFWSpklaK+lCSSslLZS0Z5XjrpJ0fNpeK+lcSUvSMXtJ6gA+DXxR0jJJkyWNkvTvkhal1yHp+HMk/VDSncAPmzV2M7P+rpkzm6OAxyLi/QCShgMXAOsjYl9JHwcuBo7toZ11ETFe0meBGRHxSUmXA89HxEWp7f8HfCsifiXpLcBc4F3p+LHAoRHxYsNHaGZmVTXzms1K4H2SLpA0OSLWp/LrKt4n1dHOjel9MdBRo84U4DuSlgE3A8Mk7ZT23Vwr0EiaLqlTUuemDeurVTEzs63QtJlNRDwgaTxwDPB1SfO6dlVWq6OpP6X3TdTu/xuAgyPipcpCSQAvbKGPs4BZADuMHlNPX8zMrA7NvGazO7AhIq4BZgLj065pFe93b2XzzwFDKz7/Avh8xXeP28p2zcysAZp5zWZfYKakV4GNwGeA2cDOklZQzFhO3Mq2fwLMlnQcRZD5AnBpancgMJ/iJgIzM2sBRbRutUjSWmBCRKxrWSdq2GH0mBh98sVZ2vaz0cysr5K0OCImdC8v5S91mplZ39LSX+qMiI5Wfr+ZmTVH6Z8g0Cr77jGcTi93mZk1hJfRzMwsOwcbMzPLzsHGzMyy8zWbGpwW2syscTyzMTOz7BxszMwsOwcbMzPLrm2CjaQRKYdN1+fDJc1pZZ/MzKw+bRNsgBHAZ3usVSdJvjnCzKxJShtsJP1NSh+9StIZwPnAO1Lq55mp2k6SZku6X9K1SglrJB0o6Q5JiyXNlTQ6ld8u6WJJncDprRmZmVn/U8qf7iUdCJwKvBsQcC/wMWCfiBiX6hwOHADsDTwG3AkcIule4BLguIh4StI04DzgtNT89tWeSJranA5MBxgwbFSewZmZ9UOlDDbAocBNEfECgKQbgclV6i2MiEdSnWUUaaL/COwD3JImOgOAxyuOub7WlzpTp5lZHmUNNvX6U8V2V5poAasjYlKNY2qmhTYzszzKes1mAfDXkgZLGgJ8kGKZbOiWDwNgDTBK0iQASdtJ2jtfV83MrCelnNlExBJJVwELU9EVEbFY0p2SVgE/A6o+SyYiXpZ0PPDPkoZTjPFiYHUTum5mZlW0NC10mTkttJlZ7zkttJmZtUwpl9HKwJk6zcwaxzMbMzPLzsHGzMyyc7AxM7PsfM2mhpyZOvsS31lnZvXwzMbMzLJzsDEzs+wcbMzMLLtswUbSZEmrU/6ZQbm+Zwvf/2lJH2/295qZ2evlvEHgJOCbEXFNPZVT4jNFxKuN+PKIuLwR7ZiZ2bbrcWYj6UuSvpC2vyXp1rR9ZMqOeZmkzjSLOTft+yRwAvA1SddWtLNI0oqKeh2S1kj6AbAKeLOkmSk758qU+AxJh6csm9Wycq6VdGGqv1DSnqn8HEkz0vbtki5I+x+QVC03jpmZZVLPMtoC/py4bAJFKubtUtl84Kz00LX9gL+QtF9EXAHcDHwpIk6SNBUYAxwEjAMOlHRYanMM8N2I2Du1Pw7YH5gCzOxK6UyRlfMMYCzwduCQij6uj4h9ge9QPOG5moERcVBq4+xqFSRNT4Gzc9OG9XX80ZiZWT3qCTaLKYLDMIpkZXdTBIXJFIHoBElLgKUUKZrHVmljanotBZYAe1EEGYDfRcQ9aftQ4LqI2BQRTwJ3ABPTvoUR8UhaZuvKytnluor3WknTbqwYT0e1ChExKyImRMSEAYOH12jGzMx6q8drNhGxUdJvgVOAu4AVwBHAnsCLwAxgYkQ8k3LQ7FilGVFcv/neZoVSB/VnzqyWlfO1btbYrnZ892PNzCyzeu9GW0ARVOan7U9TzFKGUQSL9ZJ2A46ucfxc4DRJOwFI2kPSG2t8zzRJAySNAg7jzwnUtmRaxfvd9Q3JzMyapd6f8BcAZwF3R8QLkl4CFkTEcklLgfuBhylSN79ORPxC0ruAu9N1/eeBj1HMMirdRLEMtpxihvLliHhC0l499G9nSSsoZi8n1jkmMzNrkrbP1ClpLTAhItY1st2cmTr7Ej8bzcwqOVOnmZm1TNtfKI+IjhztOlOnmVnjeGZjZmbZOdiYmVl2DjZmZpZd21+zycWZOsvJd7+ZtSfPbMzMLDsHGzMzy87BxszMsmubYNPbzJspB86cnH0yM7P6tM0NArUyb0oaGBGvNLs/ZmZWv9IGmzSLmUHxQM4VwG+A5yPiIkm3U+S0ORS4TtJ84NvAEIqHcb63W1tDgEuAfYDtgHMi4sdNGoqZWb9XymAjaW/gH4D3RMQ6SSOBL3Srtn1ETJC0PcVTp6dFxKKU5O3FbnXPAm6NiNMkjQAWSvplRGyWS0fSdGA6wIBhozKMzMysfyrrNZsjgRu6nuQcEU9XqXN9en8n8HhELEp1n62yrDYVOFPSMuB2igRvb+neoDN1mpnlUcqZTZ3qzfAJRabQD0XEmlydMTOz2so6s7kV+LCkXQDSMlota4DRkiamukMldQ+ic4HPK2Vuk3RAhj6bmVkNpZzZRMRqSecBd0jaRJGCem2Nui9LmgZcImkQxfWaKd2qfQ24GFgh6Q3Ab4Fjc/XfzMw2V8pgAxARVwNX19h3eLfPi4CDu1W7Pb2IiBeBTzW6j2ZmVp+yLqOZmVkf4mBjZmbZlXYZrdWcFtrMrHE8szEzs+wcbMzMLDsvo9XgTJ39gzN/mjWHZzZmZpadg42ZmWXnYGNmZtk52JiZWXYONmZmll3Dgo2k5xvVVu52c/XVzMyq88zGzMyya3iwUWGmpFWSVqbH/yPpUkl/lbZvknRl2j4tpROop+0vSVokaYWkc1PZ+ZI+V1HnHEkzatXvof3pkjoldW7asL73gzczs6pyzGz+JzAO2J8ir8xMSaOBBcDkVGcPYGzangzM76lRSVOBMcBBqf0DJR1GkR76hIqqJwDXb6F+TU4LbWaWR45gcyhwXURsiogngTuAiaRgI2kscB/wZApCk4C76mh3anotBZYAewFjImIp8EZJu0vaH3gmIh6uVb+B4zQzszo17XE1EfGopBHAURQzmZEUs5DnI+K5OpoQ8M2I+F6VfTcAxwP/g2Km01N9MzNrohwzmwXANEkDJI0CDgMWpn33AGdQBJsFwIz0Xo+5wGmSdgKQtIekN6Z91wMfoQg4N9RR38zMmijHzOYmiqWx5UAAX46IJ9K+BcDUiHhI0u8oZjd1BZuI+IWkdwF3SwJ4HvgY8IeIWC1pKPBoRDzeU/0GjdPMzOqkiGh1H0pph9FjYvTJF7e6G5aZn/ps1liSFkfEhO7lTjFQgzN1mpk1TimCjaRdgHlVdr03Iv672f0xM7PGKkWwSQFlXKv7YWZmefhxNWZmll0pZjZl5LTQVja+mcHamWc2ZmaWnYONmZll52BjZmbZtXWwkTRC0mfrqHe7pNf9kpGZmTVH6YONpC3dxDAC6DHYmJlZazU12EgaIumnkpan5GrTJE2UdFcqWyhpqKRTJN0s6VZgnqSdJM2TtCQlZDsuNXk+8A5JyyTNTN/xd6nOcknnV3z9h1P7D0ia3L1vZmaWT7NvfT4KeCwi3g8gaThFvplpEbFI0jDgxVR3PLBfRDydZjcfjIhnJe0K3CPpZuBMYJ+IGJfaOxo4Dnh3RGyQNLLiuwdGxEGSjgHOpkjsthlJ04HpAAOGjWr86M3M+qlmL6OtBN4n6YI0u3gL8HhELAKIiGcj4pVU95aIeDptC/iGpBXALykyfe5Wpf0pwPcjYkNq7+mKfTem98VAR7XOOVOnmVkeTZ3ZRMQDksYDxwBfB27dQvUXKrZPAkYBB0bERklrgR17+fV/Su+b8C+zmpk1VbOv2ewObIiIa4CZwLuB0ZImpv1Da9wQMJwib81GSUcAb03lzwFDK+rdApwqaXBqbyRmZtZyzf4Jf19gpqRXgY3AZyiWyC6RNIjies3rrqUA1wI/kbQS6ATuh+IBnpLulLQK+FlEfEnSOKBT0svAfwJ/n31UZma2RU6eVoOTp1nZ+Nlo1g5qJU8r/e/ZmJlZ+/OF8hqcqdPMrHE8szEzs+wcbMzMLDsHGzMzy87XbGpwpk4rM9+ZZu3GMxszM8vOwcbMzLJzsDEzs+z6RbCRtDalJjAzsxZou2DTQ+ZOMzMroVL+xy3p48AMIIAVFGkBXgIOAO6U9CPg2xRpBl4ETo2INZIGABdQJGl7FfiXiLikot1BFHltboyIf2nikMzM+rXSBRtJewP/ALwnItalNAH/BLwplW1KGT0nR8QrkqYA3wA+RJFlswMYl/ZVphjYCfgR8IOI+EGN73amTjOzDEoXbIAjgRsiYh0U2TYlkco2pTrDgasljaGY/WyXyqcAl3dl++yWqfPHwIURcW2tL46IWcAsKJ763LghmZn1b+10zaYyc+fXgNsiYh/gA9SXtfNO4CilyGVmZs1TxmBzK/BhSbtAzWybw4FH0/YpFeW3AJ/quomg27FfBZ4BLm10h83MbMtKF2wiYjVwHnCHpOUU12u6uxD4pqSlbL4UeAXwe2BFOvaj3Y47HRgk6cLG99zMzGpxps4anKnTyszPRrOycqZOMzNrGQcbMzPLroy3PpeC00KbmTWOZzZmZpadg42ZmWXnZbQanKnT2onvTrOy88zGzMyyc7AxM7PsHGzMzCw7BxszM8uu7YKNpDMkDa6j3hWSxjajT2ZmtmVtF2yAM4Aeg01EfDIi7mtCf8zMrAelDjaShkj6qaTlklZJOhvYHbhN0m2pzmWSOiWtlnRuxbG3S5qQtp+XdF5q5x5Ju7VmRGZm/VOpgw1wFPBYROyfEqVdDDwGHBERR6Q6Z6UnjO4H/IWk/aq0MwS4JyL2B+YD/7val0mangJX56YN6xs+GDOz/qrswWYl8D5JF0iaHBHVIsAJkpYAS4G9gWrXaV4G5qTtxUBHtS+LiFkRMSEiJgwYPHzbe29mZkDJnyAQEQ9IGg8cA3xd0rzK/ZLeBswAJkbEM5KuonqK6I3x58Q9myj5uM3M+ppSz2wk7Q5siIhrgJnAeOA5YGiqMgx4AVifrsMc3ZKOmpnZFpX9J/x9gZmSXgU2Ap8BJgE/l/RYRByRUkPfDzwM3Nm6rpqZWS1OC12D00JbO/GDOK0snBbazMxapuzLaC3jTJ1mZo3jmY2ZmWXnYGNmZtk52JiZWXa+ZlOD00Kb2dbwnYHVeWZjZmbZOdiYmVl2DjZmZpZd2wcbSaekZ6j1VOc7zeqTmZltru2DDXAKRUI1MzMrqdIFG0kdku6XdK2kX0uaLWmwpK9KWpQyds5S4XhgAnCtpGWSBkmaKOmulJVzoaSuJ0TvLunnkh6UdGELh2hm1u+ULtgk7wS+GxHvAp4FPgt8JyImpoydg4BjI2I20AmcFBHjKHLVXA+cnrJyTgFeTG2OA6ZRPEl6mqQ3d/9SZ+o0M8ujrMHm4YjoShdwDXAocISkeyWtBI6kyMrZ3TuBxyNiEUBEPBsRr6R98yJifUS8BNwHvLX7wc7UaWaWR1l/qbN73oMAvgtMiIiHJZ1D9YycW/Knim1n6zQza6KyzmzeImlS2v4o8Ku0vU7STsDxFXUrM3euAUZLmgggaagkBxUzsxYr63/Ea4DPSbqSYsnrMmBnYBXwBLCoou5VwOWSXqTI4jkNuETSIIrrNVOa2G8zM6uidJk6JXUAc9KNAC3jTJ1mtjX6+7PRnKnTzMxapnTLaBGxFmjprAacqdPMrJE8szEzs+wcbMzMLDsHGzMzy65012zKwpk6zayV+tpdbZ7ZmJlZdg42ZmaWnYONmZll1/BgI+kcSTMk/aOkXj8qRtLhkuY0ul8V7XdIWpWrfTMze71sNwhExFdztW1mZu2lITMbSWdJekDSryhyyiDpqpRJE0nnS7pP0gpJF1XsvzwlK3tA0rFV2j1I0t2Slqbsm11tD5B0UcrauULS51P5gZLukLRY0lxJoyvKl0taDnyuEWM2M7P6bfPMRtKBwEcoMmEOBJYAiyv27wJ8ENgrIkLSiIrDO4CDgHcAt0nas1vz9wOTI+KVtCT3DeBDwPR07Li0b6Sk7YBLgOMi4ilJ04DzgNOA7wP/JyLmS5q5hbFMT20zYNiorfrzMDOz12vEMtpk4KaI2AAg6eZu+9cDLwH/mq7FVF6P+beIeBV4UNJ/AXt1O3Y4cLWkMRQJ1LZL5VOAy7uycEbE05L2oXim2i2SAAYAj6fgNiIi5qdjfwgcXW0gETELmAXFU5978WdgZmZbkP1utBQQDgJmA8cCP6/c3b16t89fA25L6QY+wJazcwpYHRHj0mvfiJi6bb03M7NGaESwmQ/8taRBkoZSBIXXpMyawyPiP4EvAvtX7P6wpDdIegfwdoqkaZWGA4+m7VMqym8BPtWVhVPSyHTsqK4Mn5K2k7R3RPwR+KOkQ9OxJ23bcM3MrLe2OdhExBLgemA58DM2z6IJRcrmOZJWUKR3/puKfb8HFqbjPh0RL3U79kLgm5KWsvmS3xXp2BXpov9HI+JlinTRF6SyZcB7Uv1TgUslLaOYAZmZWRO1LFOnpKsoMnLObkkHeuBMnWbWSu36bDRn6jQzs5Zp2VOfI+KUVn23mZk1l1MM1OC00GZmjeNlNDMzy87BxszMsvMyWg3O1Glm/VGuu+A8szEzs+wcbMzMLDsHGzMzy67fBRtn6jQza75+F2zMzKz5Sn83mqT/C3wMeAp4mCIx2y+By4HBwG+A0yLiGUnjapQfCFyZmvxFk4dgZtbvlXpmI2kiRWbO/SkSnnU93O0HwN9FxH7ASuDsHsq/D3w+IirTG5iZWZOUOtgAhwA/joiXIuI54CfAEIrMm3ekOlcDh0kaXqO8WqbOqiRNl9QpqXPThvVZBmRm1h+VPdg0VUTMiogJETFhwODhre6OmVmfUfZgcyfwAUk7poyfxwIvAM9Impzq/C/gjohYX6PcmTrNzFqs1DcIRMQiSTcDK4AnKa7DrAdOBi6XNBj4L4pMnGyh/FTgSkmBbxAwM2u6Ugeb5KKIOCcFkPnA4ohYBhzcveIWyhdT3GTQ5cu5OmtmZq/XDsFmlqSxwI7A1RGxpNUdMjOz3il9sImIj7a6D2Zmtm1KH2xaxZk6zcwap+x3o5mZWR/gYGNmZtk52JiZWXYONmZmlp2DjZmZZedgY2Zm2TnYmJlZdg42ZmaWnYONmZllp4hodR9KSdJzwJpW96MJdgXWtboTTdBfxgn9Z6weZzm9NSJGdS/042pqWxMRE3qu1t4kdXqcfUt/GavH2V68jGZmZtk52JiZWXYONrXNanUHmsTj7Hv6y1g9zjbiGwTMzCw7z2zMzCw7BxszM8vOwaYbSUdJWiPpIUlntro/20LSmyXdJuk+SaslnZ7KR0q6RdKD6X3nVC5J/5zGvkLS+NaOoHckDZC0VNKc9Pltku5N47le0vapfIf0+aG0v6OV/e4tSSMkzZZ0v6RfS5rUF8+ppC+mv7erJF0nace+cE4lXSnpD5JWVZT1+vxJOjnVf1DSya0YS2842FSQNAC4FDgaGAucKGlsa3u1TV4B/jYixgIHA59L4zkTmBcRY4B56TMU4x6TXtOBy5rf5W1yOvDris8XAN+KiD2BZ4BPpPJPAM+k8m+leu3k28DPI2IvYH+KMfepcyppD+ALwISI2AcYAHyEvnFOrwKO6lbWq/MnaSRwNvBu4CDg7K4AVVoR4Vd6AZOAuRWfvwJ8pdX9auD4fgy8j+LJCKNT2WiKX2AF+B5wYkX91+qV/QW8ieIf6ZHAHEAUv3U9sPu5BeYCk9L2wFRPrR5DneMcDvy2e3/72jkF9gAeBkamczQH+Mu+ck6BDmDV1p4/4ETgexXlm9Ur48szm811/QXv8kgqa3tpWeEA4F5gt4h4PO16Atgtbbfz+C8Gvgy8mj7vAvwxIl5JnyvH8to40/71qX47eBvwFPD9tGR4haQh9LFzGhGPAhcBvwcepzhHi+mb5xR6f/7a7rw62PQDknYC/h04IyKerdwXxY9FbX3/u6RjgT9ExOJW96UJBgLjgcsi4gDgBf685AL0mXO6M3AcRXDdHRjC65ee+qS+cP6qcbDZ3KPAmys+vymVtS1J21EEmmsj4sZU/KSk0Wn/aOAPqbxdx38I8FeS1gI/olhK+zYwQlLX8/8qx/LaONP+4cB/N7PD2+AR4JGIuDd9nk0RfPraOZ0C/DYinoqIjcCNFOe5L55T6P35a7vz6mCzuUXAmHTHy/YUFyRvbnGftpokAf8K/Doi/qli181A190rJ1Ncy+kq/3i6A+ZgYH3F1L60IuIrEfGmiOigOGe3RsRJwG3A8ala93F2jf/4VL8tfpKMiCeAhyW9MxW9F7iPPnZOKZbPDpY0OP097hpnnzunSW/P31xgqqSd0yxwaiorr1ZfNCrbCzgGeAD4DXBWq/uzjWM5lGI6vgJYll7HUKxlzwMeBH4JjEz1RXE33m+AlRR3ArV8HL0c8+HAnLT9dmAh8BBwA7BDKt8xfX4o7X97q/vdyzGOAzrTef0PYOe+eE6Bc4H7gVXAD4Ed+sI5Ba6juA61kWKm+omtOX/AaWm8DwGntnpcPb38uBozM8vOy2hmZpadg42ZmWXnYGNmZtk52JiZWXYONmZmlp2DjZmZZedgY2Zm2f1/rmIm0U0N2D4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHCJr5IFDctF"
      },
      "source": [
        "# Prepare Dataset into Train and Val and and Test (60:20:20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yed9nTLUVXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2166e083-42d9-4577-c658-f835eb8bde86"
      },
      "source": [
        "X = data.image_path\n",
        "y = data.label\n",
        "\n",
        "n_splits = 1  # A single split in this case\n",
        "sss_test = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.20, random_state=42) \n",
        "\n",
        "for train_val_index, test_index in sss_test.split(X, y):\n",
        "  X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
        "  y_train_val, y_test = y.iloc[train_val_index], y.iloc[test_index]\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "k_folds_splits = 5\n",
        "\n",
        "skf = StratifiedKFold(n_splits=k_folds_splits, random_state=42)\n",
        "\n",
        "print(skf)\n",
        "\n",
        "k_folds_train = {}\n",
        "k_folds_val = {}\n",
        "\n",
        "y_train_val_iter = y_train_val.copy()\n",
        "\n",
        "i = 1\n",
        "for train_index, val_index in skf.split(X_train_val, y_train_val_iter.astype('int')):\n",
        "  # print(\"TRAIN:\", train_index, \"Val:\", val_index)\n",
        "  X_train, X_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
        "  y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
        "  k_folds_train[f'{i}-fold'] = [X_train, y_train]\n",
        "  k_folds_val[f'{i}-fold'] = [X_val, y_val]\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IynS-DyeOQD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad42346-6708-4516-c832-7cc3307beaac"
      },
      "source": [
        "print(len(X), len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5944 5944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uysrNZjwUhRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacaead3-6ae4-4ac7-f2fb-a6e4477b4e5c"
      },
      "source": [
        "for k in range(k_folds_splits):\n",
        "  print(f'Train {k+1}-k-fold - Values', len(list(k_folds_train.values())[k][0]))\n",
        "  print(f'Train {k+1}-k-fold - Labels', len(list(k_folds_train.values())[k][1]))\n",
        "  print(f'Val {k+1}-k-fold - Values', len(list(k_folds_val.values())[k][0]))\n",
        "  print(f'Val {k+1}-k-fold - Labels', len(list(k_folds_val.values())[k][1]))\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train 1-k-fold - Values 3804\n",
            "Train 1-k-fold - Labels 3804\n",
            "Val 1-k-fold - Values 951\n",
            "Val 1-k-fold - Labels 951\n",
            "\n",
            "\n",
            "Train 2-k-fold - Values 3804\n",
            "Train 2-k-fold - Labels 3804\n",
            "Val 2-k-fold - Values 951\n",
            "Val 2-k-fold - Labels 951\n",
            "\n",
            "\n",
            "Train 3-k-fold - Values 3804\n",
            "Train 3-k-fold - Labels 3804\n",
            "Val 3-k-fold - Values 951\n",
            "Val 3-k-fold - Labels 951\n",
            "\n",
            "\n",
            "Train 4-k-fold - Values 3804\n",
            "Train 4-k-fold - Labels 3804\n",
            "Val 4-k-fold - Values 951\n",
            "Val 4-k-fold - Labels 951\n",
            "\n",
            "\n",
            "Train 5-k-fold - Values 3804\n",
            "Train 5-k-fold - Labels 3804\n",
            "Val 5-k-fold - Values 951\n",
            "Val 5-k-fold - Labels 951\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXWZC0DZFVcy"
      },
      "source": [
        "Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb8m9VeiFFOE",
        "outputId": "6a358e05-00c9-416b-e804-1db326301baf"
      },
      "source": [
        "# check if split correct\n",
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "print(len(X_val))\n",
        "print(len(y_val))\n",
        "print(len(X_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3804\n",
            "3804\n",
            "951\n",
            "951\n",
            "1189\n",
            "1189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "2NyN0cJcFy5o",
        "outputId": "e61a6907-8852-4531-ca4a-ba8b93dc89ad"
      },
      "source": [
        "y_train_val.value_counts().plot(kind='bar', figsize=(14, 8)) # plotting the number of occurrences of each label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fddde80cad0>"
            ]
          },
          "metadata": {},
          "execution_count": 285
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "_TNti1UfF9aF",
        "outputId": "d8ff3ab3-b2f9-4fa2-846f-0945bf101af7"
      },
      "source": [
        "y_test.value_counts().plot(kind='bar', figsize=(14, 8)) # plotting the number of occurrences of each label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fddde728110>"
            ]
          },
          "metadata": {},
          "execution_count": 286
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnK5e7AoLOqN"
      },
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z79LNvBLalB"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evscwIrCNRbx"
      },
      "source": [
        "def load_image(infilename, infilegrayscale):\n",
        "    \"\"\"\n",
        "    This function loads an image into memory when you give it the path of the image\n",
        "    \"\"\"\n",
        "    if infilegrayscale:\n",
        "      img = Image.open(infilename).convert('L')\n",
        "    else:\n",
        "      img = Image.open(infilename)\n",
        "    #data = np.asarray(img)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7sNStzvMbV5"
      },
      "source": [
        "class WaferDataset(Dataset):\n",
        "    def __init__(self, path, labels, model=None):\n",
        "        self.X = path\n",
        "        self.y = labels\n",
        "        self.model = model\n",
        "        if self.model in [\"BaseNet\", \"RegNet\", \"VicNet\"]:\n",
        "          self.infilegrayscale = True\n",
        "        else:\n",
        "          self.infilegrayscale = False\n",
        "\n",
        "        # preprocessing\n",
        "        if model in [\"ResNet18\", \"VGG16\"]: # validation\n",
        "            self.preprocess = transforms.Compose([\n",
        "              transforms.Resize(244),\n",
        "              transforms.CenterCrop(224),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # duplicate channel as Resnet18 based on RGB\n",
        "              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "              # Data augmentation\n",
        "              transforms.RandomHorizontalFlip(p=0.5),\n",
        "              transforms.RandomRotation(30),\n",
        "              transforms.RandomVerticalFlip(p=0.5)\n",
        "            ])\n",
        "        elif model in [\"BaseNet\", \"RegNet\", \"VicNet\", \"MaxNet\"]:\n",
        "          self.preprocess = transforms.Compose([\n",
        "              transforms.Resize(244),\n",
        "              transforms.CenterCrop(224),\n",
        "              transforms.ToTensor(),\n",
        "              # Data augmentation\n",
        "              transforms.RandomHorizontalFlip(p=0.5),\n",
        "              transforms.RandomRotation(30),\n",
        "              transforms.RandomVerticalFlip(p=0.5)\n",
        "            ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return (len(self.X))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = load_image(self.X.iloc[i], self.infilegrayscale)\n",
        "        label = self.y.iloc[i]\n",
        "        if self.model is not None:\n",
        "          image = self.preprocess(image)\n",
        "        # print(image.shape)\n",
        "        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP9gy1lucgvo"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05jsA8ZDVrTc"
      },
      "source": [
        "## BaseNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfaq69uiVzYn"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UtQ5LQ5V00M"
      },
      "source": [
        "from torchvision import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VhrBUwAVtAu"
      },
      "source": [
        "class BaseNet(nn.Module):\n",
        "  def __init__(self, input_shape=(1, 224, 224)):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=config['kernel_size'])\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=config['kernel_size'])\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=config['kernel_size'])\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    n_size = self._get_conv_output(input_shape)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=n_size, out_features=config['fc_layer_size'])\n",
        "    self.fc2 = nn.Linear(in_features=config['fc_layer_size'], out_features=len(lb.classes_))\n",
        "\n",
        "  def _get_conv_output(self, shape):\n",
        "    batch_size = 1\n",
        "    input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "    output_feat = self._forward_features(input)\n",
        "    n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "    return n_size\n",
        "  \n",
        "  def _forward_features(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    return x\n",
        "  \n",
        "  def forward(self, x):\n",
        "      # Here, we define how an input x is translated into an output. In our linear example, this was simply (x^T * w), now it becomes more complex but\n",
        "      # we don't have to care about that (gradients etc. are taken care of by Pytorch).\n",
        "      x = self._forward_features(x)\n",
        "      # You can always print shapes and tensors here. This is very very helpful to debug.\n",
        "      # print(\"x.shape:\", x.shape)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulm4do8xV3Cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17dbe746-aeb4-4cd7-9b35-fbbfea2582c8"
      },
      "source": [
        "basenet = BaseNet()\n",
        "basenet = basenet.to(runtime)\n",
        "\n",
        "print(basenet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BaseNet(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=86528, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=11, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5EgedoI5tcb"
      },
      "source": [
        "## RegNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hp1lfTQM_NG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyFiVmYk5vSJ"
      },
      "source": [
        "class RegNet(nn.Module):\n",
        "  def __init__(self, input_shape=(1, 224, 224)):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=config['kernel_size'])\n",
        "    self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=config['kernel_size'])\n",
        "    self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=config['kernel_size'])\n",
        "    self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    n_size = self._get_conv_output(input_shape)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=n_size, out_features=config['fc_layer_size'])\n",
        "    self.fc2 = nn.Linear(in_features=config['fc_layer_size'], out_features=len(lb.classes_))\n",
        "\n",
        "    self.softmax = nn.LogSoftmax(dim=1) \n",
        "    self.dropout = nn.Dropout(config['dropout'])\n",
        "\n",
        "  def _get_conv_output(self, shape):\n",
        "    batch_size = 1\n",
        "    input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "    output_feat = self._forward_features(input)\n",
        "    n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "    return n_size\n",
        "  \n",
        "  def _forward_features(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    return x\n",
        "  \n",
        "  def forward(self, x):\n",
        "      x = self._forward_features(x)\n",
        "      # print(\"x.shape:\", x.shape)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.softmax(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D_NlFSi7cfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292a0067-a8e4-4ccd-800a-89f8ac4e65e0"
      },
      "source": [
        "regnet = RegNet()\n",
        "regnet = regnet.to(runtime)\n",
        "\n",
        "print(regnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RegNet(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (batchnorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=86528, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=11, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            "  (dropout): Dropout(p=0, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U099hsjBpxOA"
      },
      "source": [
        "## VicNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50X-zroWpw3K"
      },
      "source": [
        "class resBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
        "      super().__init__()\n",
        "      self.in_channels = in_channels\n",
        "      self.out_channels = out_channels\n",
        "      self.kernel_size = kernel_size\n",
        "      self.stride = stride\n",
        "      self.downsample = None\n",
        "\n",
        "      if stride != 1 or in_channels != out_channels:\n",
        "        self.downsample = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, 1, self.stride),\n",
        "                                        nn.BatchNorm2d(self.out_channels))\n",
        "\n",
        "      self.block = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, self.kernel_size, self.stride, padding=1),\n",
        "                                nn.BatchNorm2d(self.out_channels),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(self.out_channels, self.out_channels, self.kernel_size, 1, padding=1),\n",
        "                                nn.BatchNorm2d(self.out_channels))\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "                               \n",
        "    def forward(self, x):\n",
        "      skip = x\n",
        "      x = self.block(x)\n",
        "      if self.downsample is not None:\n",
        "        skip = self.downsample(skip)\n",
        "      x += skip\n",
        "      x = self.relu(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfInPwMQqYTK"
      },
      "source": [
        "class VicNet(nn.Module):\n",
        "  def __init__(self, input_shape=(1, 224, 224)):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=config['kernel_size'])\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=config['kernel_size'])\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
        "    self.dropout = nn.Dropout2d(config['dropout'])\n",
        "    self.block1 = resBlock(in_channels=32, out_channels=32)\n",
        "    self.block2 = resBlock(in_channels=32, out_channels=64, stride=2)\n",
        "    self.block3 = resBlock(in_channels=64, out_channels=128, stride=2)\n",
        "    self.block4 = resBlock(in_channels=128, out_channels=256)\n",
        "    self.avg_pool = nn.AvgPool2d(kernel_size=2)\n",
        "\n",
        "    n_size = self._get_conv_output(input_shape)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=n_size, out_features=config['fc_layer_size'])\n",
        "    self.fc2 = nn.Linear(in_features=config['fc_layer_size'], out_features=len(lb.classes_))\n",
        "\n",
        "  def _get_conv_output(self, shape):\n",
        "    batch_size = 1\n",
        "    input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "    output_feat = self._forward_features(input)\n",
        "    n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "    return n_size\n",
        "  \n",
        "  def _forward_features(self, x):\n",
        "    x = self.max_pool(F.relu(self.conv1(x)))\n",
        "    x = self.max_pool(F.relu(self.conv2(x)))\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    x = self.avg_pool(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self._forward_features(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TB8u-Ges9nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9a02c8-d565-4ec0-9c51-091065d86c23"
      },
      "source": [
        "vicnet = VicNet()\n",
        "vicnet = vicnet.to(runtime)\n",
        "\n",
        "print(vicnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VicNet(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout2d(p=0, inplace=False)\n",
            "  (block1): resBlock(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (block2): resBlock(\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (block3): resBlock(\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (block4): resBlock(\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (fc1): Linear(in_features=12544, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=11, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXqeCtojCJ7R"
      },
      "source": [
        "## MaxNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU0Q_s6GCJV6"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class ConnectionBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c, stride):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pathA = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=3,\n",
        "                stride=stride,\n",
        "                padding=1),\n",
        "            nn.Dropout2d(config['dropout']),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1),\n",
        "            nn.Dropout2d(config['dropout']),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.pathB = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=5,\n",
        "                stride=stride,\n",
        "                padding=2),\n",
        "            nn.Dropout2d(config['dropout']),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=5,\n",
        "                stride=1,\n",
        "                padding=2),\n",
        "            nn.Dropout2d(config['dropout']),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.pathC = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=9,\n",
        "                stride=stride,\n",
        "                padding=4),\n",
        "            nn.Dropout2d(config['dropout']),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=9,\n",
        "                stride=1,\n",
        "                padding=4),\n",
        "            nn.Dropout2d(config['dropout']),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.pathSkip = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=1,\n",
        "                stride=stride),\n",
        "            nn.Dropout2d(config['dropout']),\n",
        "            nn.BatchNorm2d(num_features=out_c))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pathA(x) + self.pathB(x) + self.pathC(x) + self.pathSkip(x)\n",
        "\n",
        "\n",
        "class MaxNet(nn.Module):\n",
        "    def __init__(self, out_classes=len(lb.classes_), input_shape=(1, 224, 224)):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            ConnectionBlock(in_c=64, out_c=64, stride=1),\n",
        "            ConnectionBlock(in_c=64, out_c=128, stride=2),\n",
        "            ConnectionBlock(in_c=128, out_c=256, stride=2),\n",
        "            ConnectionBlock(in_c=256, out_c=512, stride=2),\n",
        "            nn.AvgPool2d(kernel_size=(2, 2)),\n",
        "            Flatten(),\n",
        "            nn.Linear(in_features=4608, out_features=config['fc_layer_size']),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config['dropout']),\n",
        "            nn.Linear(in_features=config['fc_layer_size'], out_features=config['fc_layer_size']),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=config['fc_layer_size'], out_features=out_classes),\n",
        "            #nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tLRLdflCeSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683fbd65-d0d9-4350-f705-83149d3509f8"
      },
      "source": [
        "maxnet = MaxNet()\n",
        "maxnet = maxnet.to(runtime)\n",
        "\n",
        "print(maxnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MaxNet(\n",
            "  (net): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): ConnectionBlock(\n",
            "      (pathA): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathB): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathC): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathSkip): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): ConnectionBlock(\n",
            "      (pathA): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathB): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathC): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(128, 128, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathSkip): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): ConnectionBlock(\n",
            "      (pathA): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathB): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathC): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathSkip): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): ConnectionBlock(\n",
            "      (pathA): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathB): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathC): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (5): Dropout2d(p=0, inplace=False)\n",
            "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU()\n",
            "      )\n",
            "      (pathSkip): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): Dropout2d(p=0, inplace=False)\n",
            "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "    (9): Flatten()\n",
            "    (10): Linear(in_features=4608, out_features=256, bias=True)\n",
            "    (11): ReLU()\n",
            "    (12): Dropout(p=0, inplace=False)\n",
            "    (13): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (14): ReLU()\n",
            "    (15): Linear(in_features=256, out_features=11, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIwqSHsTMKSo"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-fbO2VhNDIJ"
      },
      "source": [
        "from torchvision import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7CrGJGbWVSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0ec411-4446-457c-84cc-d28dc8f17af5"
      },
      "source": [
        "resnet18 = models.resnet18(pretrained=True)  \n",
        "for param in resnet18.parameters():\n",
        "  param.requires_grad=False # freezes the layers to only fine-tune the last one\n",
        "\n",
        "print(resnet18)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J88gzUWMMIn"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paQQGO8DWRBK"
      },
      "source": [
        "Also try VGG16 without batch norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngO0J3gJMIzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacf4fce-c84d-453c-c8e7-f3eb91c842b9"
      },
      "source": [
        "vgg16 = models.vgg16_bn(pretrained=True)\n",
        "for param in vgg16.features.parameters():\n",
        "  param.requires_grad=False # freezes the layers to only fine-tune the last one\n",
        "\n",
        "print(vgg16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTjBLOixcu2Y"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51C8Avb0Su-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48,
          "referenced_widgets": [
            "7a6e5f27ae4f4b8badb8b4a4526cd3ac",
            "054f0c3df1214e0c81ffa79b8297b2de",
            "361f140cc9304137bbdf61236b63ab6f"
          ]
        },
        "outputId": "2d8bc5ec-d663-4850-f18c-8da26ffb9e46"
      },
      "source": [
        "list_transfer_model = ['ResNet18', 'VGG16']\n",
        "\n",
        "w = widgets.Dropdown(options={'BaseNet': basenet,\n",
        "                              'ResNet18': resnet18,\n",
        "                              'RegNet': regnet,\n",
        "                              'VicNet': vicnet, \n",
        "                              'VGG16': vgg16 })\n",
        "\n",
        "\n",
        "display(w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a6e5f27ae4f4b8badb8b4a4526cd3ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(options={'BaseNet': BaseNet(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): C…"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb7nQo7zS_Bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ffaaf6-3af4-4b83-8102-b9dffa73f226"
      },
      "source": [
        "print(f'Selected Net: {w.label}')\n",
        "w.value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected Net: BaseNet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseNet(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=86528, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQJgEurThsbq"
      },
      "source": [
        "net = w.value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OST25CGClRl"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eVUz9g-3bKD"
      },
      "source": [
        "To measuse inference time: https://towardsdatascience.com/the-correct-way-to-measure-inference-time-of-deep-neural-networks-304a54e5187f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_92yNmCw0qa"
      },
      "source": [
        "def reset_weights(m):\n",
        "  '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "    print(f'Reset trainable parameters of layer = {layer}')\n",
        "    layer.reset_parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH79DyrOuIro",
        "outputId": "5f5107da-8eea-4f9f-fd27-2ffe578f9314"
      },
      "source": [
        "%%time\n",
        "early_stopping_patience = 10\n",
        "epochs = config['epochs']\n",
        "if w.label in list_transfer_model:\n",
        "  transferlearning = True\n",
        "else:\n",
        "  transferlearning = False\n",
        "\n",
        "min_val_loss = np.Inf\n",
        "\n",
        "\n",
        "# initialize the early_stopping object\n",
        "early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
        "\n",
        "print(f'Train_Val - Values', len(X_train_val))\n",
        "print(f'Train_Val - Values', len(y_train_val))\n",
        "print(f'Test - Values', len(X_test))\n",
        "print(f'Test - Values', len(y_test))\n",
        "print('\\n')\n",
        "\n",
        "train_val_data = WaferDataset(X_train_val, y_train_val, model=w.label)\n",
        "test_data = WaferDataset(X_test, y_test, model=w.label)\n",
        "\n",
        "# dataloaders\n",
        "train_val_dataloader = DataLoader(train_val_data, batch_size=config['batch_size'], shuffle=True)  # shuffle here instead of in model\n",
        "test_dataloader = DataLoader(test_data, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "# Init the neural network\n",
        "if transferlearning:\n",
        "  # Setup / deepcopy transfer learning model based on selected backbone transfer model \n",
        "  net = copy.deepcopy(w.value)\n",
        "  # Add Classifier Layer to backbone transfer model\n",
        "  net.fc = nn.Linear(512, len(lb.classes_))\n",
        "  # Model to Cuda\n",
        "  net = net.to(runtime)\n",
        "else:\n",
        "  net = w.value\n",
        "  net.apply(reset_weights)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Define the optimizer\n",
        "if config['optimizer']=='sgd':\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
        "elif config['optimizer']=='adam':\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=config['learning_rate'])\n",
        "loss_fct = nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "acc_val = 0\n",
        "acc_train = 0\n",
        "batch_ct = 0\n",
        "example_ct = 0\n",
        "\n",
        "\n",
        "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "timings=[]\n",
        "frames = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # This command tells the neural network that it should be in training-mode now.\n",
        "  # This call is important as some functions in neural networks (e.g., dropout) should \n",
        "  # only be applied when training\n",
        "  net.train()\n",
        "\n",
        "  total=0\n",
        "  correct=0\n",
        "\n",
        "  epoch_train_loss = 0.\n",
        "  # Iterate over the dataset in chunks of size 32 (the batches)\n",
        "  for i, data in enumerate(train_val_dataloader):\n",
        "    X_batch, y_batch = data[0].to(runtime), data[1].to(runtime)\n",
        "\n",
        "    y_pred = net(X_batch)\n",
        "    loss = loss_fct(y_pred, y_batch)\n",
        "\n",
        "    example_ct += len(data)\n",
        "\n",
        "    epoch_train_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "    _,pred = torch.max(y_pred, dim=1)\n",
        "\n",
        "    #add the count of correct prediction of the batch to a correct prediction list\n",
        "    correct += torch.sum(pred==y_batch).item()\n",
        "    #add the count of all predictions of the batch to a total prediction list\n",
        "    total += y_batch.size(0)\n",
        "    #calculate accuracy of all predicted samples so far\n",
        "    acc_train = 100 * correct/total\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  epoch_train_loss = epoch_train_loss / len(train_val_dataloader.sampler)\n",
        "  train_losses.append(epoch_train_loss)\n",
        "  train_acc.append(acc_train)\n",
        "\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  total_t=0\n",
        "  correct_t=0\n",
        "\n",
        "  # Init or reset the prediction and label lists(tensors) of a epoch\n",
        "  predlist=torch.zeros(0,dtype=torch.long, device=runtime)\n",
        "  lbllist=torch.zeros(0,dtype=torch.long, device=runtime)\n",
        "\n",
        "\n",
        "  epoch_val_loss = 0. #reset epoch loss from validation\n",
        "\n",
        "  # This command tells the neural network that it should be in evaluation mode now.\n",
        "  # This call turns of special functions for training, such as dropout. \n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for X_batch_val, y_batch_val in (test_dataloader):\n",
        "      #load batch of validation data\n",
        "      X_batch_val, y_batch_val = X_batch_val.to(runtime), y_batch_val.to(runtime)\n",
        "\n",
        "      #predict batch\n",
        "      starter.record()\n",
        "      y_pred_val = net(X_batch_val)\n",
        "      ender.record()\n",
        "\n",
        "      if runtime == torch.device('cuda'):\n",
        "          torch.cuda.synchronize() \n",
        "\n",
        "      laps_time = starter.elapsed_time(ender)\n",
        "      \n",
        "      timings.append(laps_time / X_batch_val.size(0))\n",
        "      frames.append(X_batch_val.size(0) / laps_time)\n",
        "\n",
        "      \n",
        "      loss_val = loss_fct(y_pred_val.squeeze(), y_batch_val)\n",
        "      # append loss of batch to epoch loss\n",
        "      epoch_val_loss += loss_val.item() * X_batch_val.size(0)\n",
        "                                            \n",
        "      _,pred_t = torch.max(y_pred_val, dim=1)\n",
        "\n",
        "      #add the count of correct prediction of the batch to a correct prediction list\n",
        "      correct_t += torch.sum(pred_t==y_batch_val).item()\n",
        "      #add the count of all predictions of the batch to a total prediction list\n",
        "      total_t += y_batch_val.size(0)\n",
        "      #calculate accuracy of all predicted samples so far\n",
        "      acc_val = 100 * correct_t/total_t\n",
        "\n",
        "      # Concatenate the prediction of a batch to list of all prediction of a epoch\n",
        "      predlist=torch.cat([predlist,pred_t.view(-1).to(runtime)])\n",
        "      lbllist=torch.cat([lbllist,y_batch_val.view(-1).to(runtime)])\n",
        "\n",
        "    # early_stopping needs the validation loss to check if it has decresed, \n",
        "    # and if it has, it will make a checkpoint of the current model\n",
        "\n",
        "    epoch_val_loss = epoch_val_loss / len(test_dataloader.sampler)\n",
        "    val_losses.append(epoch_val_loss)\n",
        "    val_acc.append(acc_val)\n",
        "\n",
        "    print('Avg execution time (ms): {:.3f}'.format(np.mean(timings)))\n",
        "    print('Avg frames per seconds (fps): {:.3f}'.format(np.mean(frames)))\n",
        "    print('Epoch: {} ->  Train loss: {} Val loss: {} Train Accuracy: {} Val Accuracy: {}'.format(epoch, epoch_train_loss, epoch_val_loss, acc_train, acc_val))\n",
        "\n",
        "\n",
        "  early_stopping(epoch_val_loss, net)\n",
        "  \n",
        "  if early_stopping.early_stop:\n",
        "    print(\"----- EARLY STOPPING -----\")\n",
        "    break\n",
        "\n",
        "y_true = lbllist.cpu().numpy()\n",
        "y_pred = predlist.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train_Val - Values 4755\n",
            "Train_Val - Values 4755\n",
            "Test - Values 1189\n",
            "Test - Values 1189\n",
            "\n",
            "\n",
            "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=86528, out_features=256, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=256, out_features=11, bias=True)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edsxq3kAIJ3H"
      },
      "source": [
        "# load the last checkpoint with the best model\n",
        "net.load_state_dict(torch.load('checkpoint.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jshUiv9GNpf"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xigUlFrw9w6"
      },
      "source": [
        "# Confusion matrix\n",
        "conf_mat=confusion_matrix(y_true, y_pred)\n",
        "print('\\n')\n",
        "print(f'Total Prediction: {len(predlist)}')\n",
        "print(f'Correct Prediction: {sum(conf_mat.diagonal())}')\n",
        "print('Confusion matrix')\n",
        "print(conf_mat)\n",
        "\n",
        "# Precision, Recall, F1-score\n",
        "class_report_print = classification_report(y_true, y_pred)\n",
        "print(class_report_print)\n",
        "class_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
        "print(f'Overall precision: {class_report_dict[\"weighted avg\"][\"precision\"]}')\n",
        "print(f'Overall recall: {class_report_dict[\"weighted avg\"][\"recall\"]}')\n",
        "print(f'Overall f1-score: {class_report_dict[\"weighted avg\"][\"f1-score\"]}')\n",
        "print('\\n')\n",
        "\n",
        "# Per-class precision, recall, F1-score\n",
        "class_precision=[]\n",
        "class_recall=[]\n",
        "class_f1=[]\n",
        "for i in range(len(sel_classes)):\n",
        "  class_precision.append(class_report_dict[str(i)]['precision'])\n",
        "  class_recall.append(class_report_dict[str(i)]['recall'])\n",
        "  class_f1.append(class_report_dict[str(i)]['f1-score'])\n",
        "print(f'Class precision: {class_precision}')\n",
        "print(f'Class recall: {class_recall}')\n",
        "print(f'Class f1-score: {class_f1}')\n",
        "print('\\n')\n",
        "\n",
        "# Per-class accuracy\n",
        "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
        "overall_accuracy = 100 * sum(conf_mat.diagonal()) / len(predlist)\n",
        "print(f'Per-class accuracy: {class_accuracy}')\n",
        "print(f'Overall accuracy: {overall_accuracy}')\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKRi11HDNFHW"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5KOs1IRFF88"
      },
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_losses)+1),train_losses, label='Training Loss')\n",
        "plt.plot(range(1,len(val_losses)+1),val_losses,label='Validation Loss')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minpos = val_losses.index(min(val_losses))+1 \n",
        "plt.axvline(minpos, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "#plt.ylim(0, 0.5) # consistent scale\n",
        "#plt.xlim(0, len(train_losses)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#fig.savefig('loss_plot.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4jndvOo0mt8"
      },
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_acc)+1),train_acc, label='Training Accuracy')\n",
        "plt.plot(range(1,len(val_acc)+1),val_acc,label='Validation Accuracy')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minpos = val_losses.index(min(val_losses))+1 \n",
        "plt.axvline(minpos, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "# draw overall accuracy\n",
        "overall_acc = overall_accuracy = 100 * sum(conf_mat.diagonal()) / len(predlist)\n",
        "plt.axhline(overall_acc, linestyle='-.', color='g', label='Overall Accuracy')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "#plt.ylim(0, 0.5) # consistent scale\n",
        "#plt.xlim(0, len(train_losses)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#fig.savefig('loss_plot.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azeQB23tixBW"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRoz-ZZFI19c"
      },
      "source": [
        "SAVE_MODEL_PATH = \"/content/drive/MyDrive/DEEPVIS/models\"\n",
        "os.path.join(SAVE_MODEL_PATH, w.label+'_'+str(len(lb.classes_))+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lngoMENpiyd9"
      },
      "source": [
        "SAVE_MODEL_PATH = \"/content/drive/MyDrive/DEEPVIS/models\"\n",
        "#torch.save(net.state_dict(), SAVE_MODEL_PATH)\n",
        "torch.save(net.state_dict(), os.path.join(SAVE_MODEL_PATH, w.label+'_'+str(len(lb.classes_))+'.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
